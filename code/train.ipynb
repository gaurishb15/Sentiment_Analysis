{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torchtext.vocab import GloVe\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math\n",
    "import spacy \n",
    "import sys \n",
    "import os\n",
    "import pandas as pd\n",
    "from typing import List, Tuple\n",
    "import csv\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"device = {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_VOCAB = {'ADJ': 0, 'ADP': 1, 'ADV': 2, 'AUX': 3, 'CONJ': 4, 'CCONJ': 5, 'DET': 6,\n",
    "                          'INTJ': 7, 'NOUN': 8, 'NUM': 9, 'PART': 10, 'PRON': 11, 'PROPN': 12,\n",
    "                          'PUNCT': 13, 'SCONJ': 14, 'SYM': 15, 'VERB': 16, '<UNK>': 17, '<PAD>': 18}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTILS.py\n",
    "\n",
    "class JustDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.data = data \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "# FUNCTIONS:\n",
    "\n",
    "def convert_pos_tags_list_into_list_of_indices_given_vocab(pos_tags_list: List[List[str]], pos_tag_vocab: dict = POS_VOCAB) -> List[List[int]]:\n",
    "\n",
    "        '''\n",
    "        given the pos_tags for all sentences converts them into a list of tensors\n",
    "        each tensor is of shape : (seq_len, )\n",
    "        if it is a padding token then i give the embedding to be 0\n",
    "        '''\n",
    "\n",
    "        print(\"Started to map pos_tags into indices using vocab\")\n",
    "\n",
    "        pos_tags_list_std = [keys for keys, values in pos_tag_vocab.items()] # contains all the pos tags we are using\n",
    "\n",
    "        all_indices_list = []\n",
    "        for pos_sent in pos_tags_list:\n",
    "            pos_index_list = []\n",
    "            for pos in pos_sent:\n",
    "                pos_index = pos_tag_vocab[pos] if pos in pos_tags_list_std else pos_tag_vocab['<UNK>']\n",
    "                pos_index_list.append(pos_index)\n",
    "            all_indices_list.append(pos_index_list)\n",
    "\n",
    "        print(\"Done mapping pos_tags to index \")\n",
    "        print(len(all_indices_list))\n",
    "\n",
    "        return all_indices_list\n",
    "\n",
    "def get_positional_encodings(masking_list: List[List[int]], sent_len: int = 64, input_dim: int=100) -> List[torch.Tensor]:\n",
    "        \n",
    "        '''\n",
    "        given a list of lists, where each sublist contains mask (0 or 1) values, 0 correspond to padding tokens\n",
    "        return the positional encoding for every sentence in the form of a list of tensors\n",
    "        '''\n",
    "\n",
    "        ans_list = []\n",
    "\n",
    "        for my_index, mask in enumerate(masking_list):\n",
    "            print('*' * 100)\n",
    "            print('\\n\\n')\n",
    "            print(f\"my_index = {my_index}\")\n",
    "            pos_encoding = get_positional_encoding_single_sent(mask, sent_len, input_dim)\n",
    "            print(\"got the positional_encoding\")\n",
    "            ans_list.append(pos_encoding)\n",
    "\n",
    "        return ans_list\n",
    "        # pos_encodings = torch.stack(ans_list)\n",
    "\n",
    "def get_positional_encoding_single_sent(mask: List[int], sent_len: int = 64, input_dim: int = 100) -> torch.Tensor:\n",
    "\n",
    "    # Create a tensor with shape (sent_len, input_dim)\n",
    "\n",
    "    print(\"Start generating positional encodings\")\n",
    "\n",
    "    position = torch.arange(0, sent_len, dtype=torch.float).unsqueeze(1)\n",
    "    div_term = torch.exp(torch.arange(0, input_dim, 2, dtype=torch.float) * -(math.log(10000.0) / input_dim))\n",
    "    encodings = torch.zeros((sent_len, input_dim))\n",
    "    encodings[:, 0::2] = torch.sin(position * div_term)\n",
    "    encodings[:, 1::2] = torch.cos(position * div_term)\n",
    "    # Apply the mask to zero out the padded tokens\n",
    "    encodings = encodings.masked_fill(torch.LongTensor(mask).unsqueeze(1) == 0, 0)\n",
    "\n",
    "    print(\"Got the positional encoding tensors\")\n",
    "\n",
    "    return encodings\n",
    "\n",
    "def convert_lemmas_list_into_tensor_embeddings(lemmas_list: List[List[str]], input_dim: int = 100) -> List[torch.Tensor]:\n",
    "\n",
    "    '''\n",
    "     given the lemmas_list from pre-processing convert it into tensors embeddings using pre-trained glove\n",
    "    '''\n",
    "    \n",
    "    assert input_dim in [50, 100, 200, 300]\n",
    "\n",
    "    print(\"Started converting the lemmas into tensor embeddings\")\n",
    "\n",
    "    glove = GloVe(name='6B', dim=input_dim, cache='glove.6B') # to convert text into embeddings\n",
    "    lemmas_embeddings_list = []\n",
    "    for sent in lemmas_list:\n",
    "        temp = []\n",
    "        for my_lemma in sent: \n",
    "            my_tensor = glove[my_lemma]\n",
    "            temp.append(my_tensor)\n",
    "        temp = torch.stack(temp)\n",
    "        lemmas_embeddings_list.append(temp)\n",
    "\n",
    "    print(\"Converted all the lemmas into embeddings\")\n",
    "\n",
    "    return lemmas_embeddings_list\n",
    "\n",
    "def prepare_data(my_dataset: My_Dataset, input_dim: int = 100):\n",
    "\n",
    "    lemmas_list, pos_tags_list, masking_list, labels_list = my_dataset.pre_process_raw_text() \n",
    "    labels_list = list(map(int, labels_list)) \n",
    "\n",
    "    lemma_tensors = convert_lemmas_list_into_tensor_embeddings(lemmas_list, input_dim)\n",
    "    positional_tensors = get_positional_encodings(masking_list, my_dataset.max_len_sent, input_dim)\n",
    "    pos_indices = convert_pos_tags_list_into_list_of_indices_given_vocab(pos_tags_list)\n",
    "\n",
    "    lemma_combine_positional = []\n",
    "    for x, y in zip(lemma_tensors, positional_tensors):\n",
    "        temp = x + y\n",
    "        lemma_combine_positional.append(temp)\n",
    "\n",
    "    data = []\n",
    "    for i in range(len(lemmas_list)):\n",
    "        temp = (lemma_combine_positional[i], pos_indices[i], labels_list[i])\n",
    "        data.append(temp)\n",
    "\n",
    "    torch.save(data, 'my_dataset_max_len_64_input_dim_100.pt')\n",
    "    print(\"Successfully saved the dataset\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My_dataset.py\n",
    "\n",
    "class My_Dataset():\n",
    "\n",
    "    def __init__(self, path_to_train_dataset_csv: str = 'train.csv'):\n",
    "        '''\n",
    "        used for the complete pre-processing part and then to get dataloaders as well after converting to tensor embeddings\n",
    "        '''\n",
    "\n",
    "        # ATTRIBUTES\n",
    "\n",
    "        self.train_csv_path = path_to_train_dataset_csv\n",
    "        self.nlp = spacy.load('en_core_web_sm') # for tokenization\n",
    "        self.max_len_sent = 64  # if the length of any sentence is bigger than this we truncate it otherwise we pad it with a padding token\n",
    "        self.padding_token = '<PAD>'\n",
    "\n",
    "        # READING THE DATASET\n",
    "\n",
    "        self.tuple_generator = self.read_csv()\n",
    "\n",
    "\n",
    "    def read_csv(self, colname_1='sentence', colname_2='gold_label'):\n",
    "\n",
    "        '''\n",
    "        this creates a generator object that yield 1 tuple of (text, label) in one iteration\n",
    "        '''\n",
    "\n",
    "        print(\"Started to read the data line by line\")\n",
    "\n",
    "        with open(self.train_csv_path, 'r') as f: \n",
    "            reader = csv.DictReader(f)\n",
    "            for row in reader:\n",
    "                yield row[colname_1], row[colname_2]\n",
    "\n",
    "    def pre_process_raw_text(self) -> Tuple[List[List[str]], List[List[str]], List[List[int]], List[int]]:\n",
    "\n",
    "        print(\"Started pre-processing the data\")\n",
    "\n",
    "        ''' \n",
    "        i have the raw_text in a list, which needs to be pre-processed\n",
    "        i will be using lemmatization and also remove the punctuation marks, stop words\n",
    "        also the make the sentence to be of equal length, add the <PAD> token to make the length equal to max_len\n",
    "        (lemma_list, pos_tags_list, masks_list)\n",
    "        '''\n",
    "\n",
    "        self.lemmas_list = [] # this is a list of lists, containing the lemmas for each sent in a list\n",
    "        self.pos_tags_list = [] # list of lists, containing the pos_tags for each sent in a list\n",
    "        self.masking_list = [] # list of lists, where each list contains 0 or 1 : 0 if the token is self.padding_token\n",
    "        self.label_list = [] # list containing the labels for each sentence\n",
    "\n",
    "\n",
    "        for my_index, my_tuple in enumerate(self.tuple_generator):\n",
    "            print('*' * 20)\n",
    "            print('\\n\\n')\n",
    "            print(f\"my_index = {my_index}, STARTED PRE_PROCESSING\\n\")\n",
    "            sent, label = my_tuple\n",
    "            my_lemmas, my_pos_tags, my_masking = self.pre_process_single_sent(sent)\n",
    "            self.lemmas_list.append(my_lemmas)\n",
    "            self.pos_tags_list.append(my_pos_tags)\n",
    "            self.masking_list.append(my_masking)\n",
    "            self.label_list.append(int(label)+1)\n",
    "            print(f\"my_index = {my_index}, COMPLETED PRE_PROCESSING\\n\\n\")\n",
    "\n",
    "        print(\"Pre-processing complete\")\n",
    "        \n",
    "        return (self.lemmas_list, self.pos_tags_list, self.masking_list, self.label_list)\n",
    "        \n",
    "    def pre_process_single_sent(self, sent: str) -> Tuple[List[str], List[str], List[int]]:\n",
    "        '''\n",
    "        given a single sentence returns a list of the lemmas in the list along with their Part of speech tags in a seperate list\n",
    "        and masking (my_lemmas, my_pos, mask), padding or truncation is also done to make the length of each sentence to be same\n",
    "        each list is of length self.max_len_sent = 256\n",
    "        '''\n",
    "\n",
    "        doc = self.nlp(sent.lower())\n",
    "        my_lemmas = [token.lemma_ for token in doc if token.is_alpha]\n",
    "        my_pos = [token.pos_ for token in doc if token.is_alpha]\n",
    "\n",
    "        len_of_my_lemmas = len(my_lemmas)\n",
    "\n",
    "        if len_of_my_lemmas >= self.max_len_sent:\n",
    "            # truncate at maximum length of the sentence\n",
    "            my_lemmas = my_lemmas[:self.max_len_sent]\n",
    "            my_pos = my_pos[:self.max_len_sent]\n",
    "            my_mask = [1 for _ in range(self.max_len_sent)]\n",
    "\n",
    "        else:\n",
    "            while len(my_lemmas) < self.max_len_sent:\n",
    "                my_lemmas.append(self.padding_token)\n",
    "                my_pos.append(self.padding_token)\n",
    "            \n",
    "            t1 = [1 for _ in range(len_of_my_lemmas)]\n",
    "            t0 = [0 for _ in range(self.max_len_sent - len_of_my_lemmas)]\n",
    "            my_mask = t1 + t0\n",
    "\n",
    "        return my_lemmas, my_pos, my_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder.py\n",
    "\n",
    "class Encoder_Sentiment_Analysis(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim: int, num_heads: int, pos_tags_vocab_len: int = len(POS_VOCAB), output_dim: int = 3, dim_feedfwd: int = 2048, dropout_prob: int=0.1, activation: str='relu', num_layers: int=4):\n",
    "\n",
    "        '''\n",
    "        first will be an Transformer encoding layer, then will use some method of pooling to convert 3D tensors to 2D tensors and\n",
    "        then passing through feed fwd network to get the logit scores and then using cross entropy loss function\n",
    "\n",
    "        '''\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # self.dataset = dataset\n",
    "        self.num_heads = num_heads\n",
    "        self.dim_feedfwd = dim_feedfwd\n",
    "        self.input_dim = input_dim\n",
    "        self.dropout_prob = dropout_prob\n",
    "        self.activation = activation\n",
    "        self.num_layers = num_layers\n",
    "        self.pos_tags_vocab_len = pos_tags_vocab_len\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.encoder_layer = TransformerEncoderLayer(d_model=self.input_dim, nhead=self.num_heads, dim_feedforward=self.dim_feedfwd,\n",
    "                                                     dropout=self.dropout_prob, activation=self.activation, batch_first=True)\n",
    "        self.encoder = TransformerEncoder(self.encoder_layer, self.num_layers)\n",
    "\n",
    "        self.feed_fwd_part_end = nn.Sequential(\n",
    "            nn.Linear(self.input_dim * 3, self.input_dim),\n",
    "            nn.ReLU(), nn.Dropout(p=0.3),\n",
    "            nn.Linear(self.input_dim, self.output_dim)\n",
    "        )\n",
    "\n",
    "        self.pos_embedding = nn.Embedding(num_embeddings=self.pos_tags_vocab_len, embedding_dim=self.input_dim, padding_idx=POS_VOCAB['<PAD>']) # to be learned\n",
    "\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        ''''\n",
    "        given a batch of inputs, give the outputs\n",
    "\n",
    "        input : will be a list of two elements\n",
    "        input_list : (lemma_embed+positional_embeddings) [Tensor], list of pos-tags mapped to their indices \n",
    "        first tensor is lemma_emebeddings + positonal_embeddings : shape = (batch_size, seq_len=256, input_dim=50)\n",
    "        second tensor is pos_indices of each sentence : shape = (batch_size, seq_len)\n",
    "        '''\n",
    "\n",
    "        pos_tags_embeds = self.pos_embedding(inputs[1])\n",
    "        features = pos_tags_embeds + inputs[0]\n",
    "\n",
    "        out = self.encoder(features)\n",
    "        # need to apply some pooling here \n",
    "\n",
    "        max_pool, _ = torch.max(out, dim=1)\n",
    "        min_pool, _ = torch.min(out, dim=1)\n",
    "        avg_pool = torch.mean(out, dim=1)\n",
    "\n",
    "        out = torch.cat([max_pool, min_pool, avg_pool], dim=1) # dim = (batch_size, 3*embed_dim)\n",
    "\n",
    "        # now shape is (batch_size, 3 * embed_dim)\n",
    "        # then pass through feed forward neural network to get some raw scores before feeding into the loss function\n",
    "\n",
    "        ans = self.feed_fwd_part_end(out)\n",
    "        return ans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 100\n",
    "batch_size = 128\n",
    "num_heads = 10\n",
    "lr=7e-5\n",
    "max_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load('my_dataset_max_len_64_input_dim_100.pt')\n",
    "train_loader = DataLoader(data, batch_size, shuffle=True)\n",
    "\n",
    "model = Encoder_Sentiment_Analysis(input_dim, num_heads)\n",
    "# model.load_state_dict(torch.load('test_set_sub_1/sentiment.params'))\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr)\n",
    "\n",
    "loss_list = []\n",
    "\n",
    "for epoch in tqdm(range(max_epochs)):\n",
    "\n",
    "    print('*' * 100)\n",
    "    print('\\n\\n')\n",
    "    print(f\"epoch = {epoch}/{max_epochs}\")\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    for step, temp in tqdm(enumerate(train_loader)):\n",
    "        # returns a list of length 3\n",
    "        lemma_tensors = temp[0]\n",
    "        pos_tensors = torch.stack(temp[1], dim=1)\n",
    "        label_tensors = temp[2]\n",
    "\n",
    "        # print(type(lemma_tensors))\n",
    "        # print(type(pos_tensors))\n",
    "        # print(type(label_tensors))\n",
    "\n",
    "        # sys.exit()\n",
    "\n",
    "\n",
    "        # fwd_pass\n",
    "        output = model([lemma_tensors.to(device), pos_tensors.to(device)])\n",
    "        loss = criterion(output, label_tensors.to(device))\n",
    "\n",
    "        # print(f\"Step = {step}/{len(train_loader)}, step_loss = {loss.item()}\")\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # update the params\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"epoch = {epoch}/{max_epochs}, epoch_loss = {epoch_loss}\")\n",
    "    print('\\n\\n')\n",
    "    print('*' * 100)\n",
    "\n",
    "    with open(\"loss.txt_mps\", \"a\") as f: \n",
    "        my_dict = {'epoch' : epoch, 'max_epochs': max_epochs, 'epoch_loss': epoch_loss}\n",
    "        f.write(f\"{my_dict}\\n\")\n",
    "    \n",
    "    loss_list.append(epoch_loss)\n",
    "\n",
    "    torch.save(model.state_dict().cpu(), 'sentiment.params_mps')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
